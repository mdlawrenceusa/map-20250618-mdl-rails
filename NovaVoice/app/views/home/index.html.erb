<div class="max-w-4xl mx-auto p-6">
  <h1 class="text-3xl font-bold text-center mb-8">Esther - Scheduling Assistant</h1>
  <p class="text-center text-gray-600 mb-2">Mike Lawrence Productions Gospel Outreach Program</p>
  <p class="text-center text-sm text-blue-600 mb-6">Website: globaloutreachevent.com | Phone: 347-300-5533</p>
  
  <!-- Connection Status -->
  <div id="connection-status" class="text-center mb-4 p-2 rounded">
    <span class="status disconnected">Connecting...</span>
  </div>
  
  <!-- Recording Controls -->
  <div class="text-center mb-8">
    <button id="record-button" class="bg-blue-500 hover:bg-blue-700 text-white font-bold py-3 px-6 rounded-lg">
      Start Recording
    </button>
  </div>
  
  <!-- Error Messages -->
  <div id="error-message" class="text-center mb-4 p-2 bg-red-100 text-red-700 rounded hidden"></div>
  
  <!-- Esther's Response -->
  <div class="bg-gray-100 p-4 rounded-lg mb-4">
    <h3 class="font-bold mb-2">Esther says:</h3>
    <div id="esther-response" class="text-gray-700 min-h-16">
      Ready to help you schedule a meeting with Mike Lawrence...
    </div>
  </div>
  
  <!-- Legacy Support -->
  <div id="status" class="text-center mb-4 text-gray-600"></div>
  <div id="transcript" class="bg-gray-100 p-4 rounded-lg min-h-32 whitespace-pre-wrap"></div>
</div>

<style>
  .status.connected {
    color: #059669;
    font-weight: bold;
  }
  
  .status.disconnected {
    color: #dc2626;
  }
  
  #record-button:disabled {
    opacity: 0.5;
    cursor: not-allowed;
  }
</style>

<script>
  let mediaRecorder;
  let audioChannel;
  let consumer;

  async function startConversation() {
    try {
      updateStatus("Requesting microphone access...");
      
      // Request microphone access with Nova Sonic optimal settings
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 16000,      // Nova Sonic prefers 16kHz
          channelCount: 1,        // Mono audio
          sampleSize: 16,         // 16-bit audio
          echoCancellation: true, // Improve audio quality
          noiseSuppression: true, // Reduce background noise
          autoGainControl: true   // Normalize audio levels
        } 
      });
      
      // Try to use a compatible audio format for Nova Sonic
      let mimeType = 'audio/webm;codecs=opus';
      if (!MediaRecorder.isTypeSupported(mimeType)) {
        mimeType = 'audio/webm';
      }
      if (!MediaRecorder.isTypeSupported(mimeType)) {
        mimeType = 'audio/wav';
      }
      
      console.log(`Using audio format: ${mimeType}`);
      mediaRecorder = new MediaRecorder(stream, { mimeType });

      updateStatus("Connecting to server...");
      
      // Import ActionCable and create consumer
      const { createConsumer } = await import('@rails/actioncable');
      consumer = createConsumer();
      
      // Subscribe to AudioStreamChannel
      audioChannel = consumer.subscriptions.create("AudioStreamChannel", {
        connected() {
          updateStatus("Connected! You can start speaking...");
          console.log("Connected to AudioStreamChannel");
        },

        disconnected() {
          updateStatus("Disconnected from server");
          console.log("Disconnected from AudioStreamChannel");
        },

        received(data) {
          console.log("Received data:", data);
          
          if (data.message && data.message.audio) {
            playAudio(data.message.audio);
          }
          
          if (data.message && data.message.text) {
            addToTranscript(`Assistant: ${data.message.text}`);
          }
          
          if (data.error) {
            addToTranscript(`Error: ${data.error}`);
            updateStatus(`Error: ${data.error}`);
          }
        }
      });

      // Send audio chunks
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0 && audioChannel) {
          const reader = new FileReader();
          reader.onload = () => {
            audioChannel.send({ audio: reader.result.split(',')[1] });
          };
          reader.readAsDataURL(event.data);
        }
      };

      mediaRecorder.start(100); // Send audio every 100ms
      document.getElementById('start-btn').disabled = true;
      document.getElementById('stop-btn').disabled = false;
      
    } catch (error) {
      console.error("Error starting conversation:", error);
      updateStatus(`Error: ${error.message}`);
    }
  }

  function stopConversation() {
    if (mediaRecorder) {
      mediaRecorder.stop();
      mediaRecorder.stream.getTracks().forEach(track => track.stop());
    }
    
    if (audioChannel) {
      audioChannel.unsubscribe();
    }
    
    if (consumer) {
      consumer.disconnect();
    }
    
    document.getElementById('start-btn').disabled = false;
    document.getElementById('stop-btn').disabled = true;
    updateStatus("Conversation stopped");
  }

  function playAudio(base64Audio) {
    try {
      console.log("Playing audio, base64 length:", base64Audio.length);
      
      // Decode base64 to binary data
      const audioData = atob(base64Audio);
      const audioBytes = new Uint8Array(audioData.length);
      for (let i = 0; i < audioData.length; i++) {
        audioBytes[i] = audioData.charCodeAt(i);
      }
      
      console.log("Audio bytes length:", audioBytes.length);
      
      // Create WAV header for 16kHz 16-bit mono PCM
      const sampleRate = 16000;
      const numChannels = 1;
      const bitsPerSample = 16;
      const dataLength = audioBytes.length;
      const headerLength = 44;
      
      const wav = new ArrayBuffer(headerLength + dataLength);
      const view = new DataView(wav);
      
      // WAV header
      view.setUint32(0, 0x52494646); // "RIFF"
      view.setUint32(4, dataLength + headerLength - 8, true);
      view.setUint32(8, 0x57415645); // "WAVE"
      view.setUint32(12, 0x666d7420); // "fmt "
      view.setUint32(16, 16, true); // PCM format size
      view.setUint16(20, 1, true); // PCM format
      view.setUint16(22, numChannels, true);
      view.setUint32(24, sampleRate, true);
      view.setUint32(28, sampleRate * numChannels * bitsPerSample / 8, true);
      view.setUint16(32, numChannels * bitsPerSample / 8, true);
      view.setUint16(34, bitsPerSample, true);
      view.setUint32(36, 0x64617461); // "data"
      view.setUint32(40, dataLength, true);
      
      // Copy audio data
      const wavBytes = new Uint8Array(wav);
      wavBytes.set(audioBytes, headerLength);
      
      const audioBlob = new Blob([wav], { type: 'audio/wav' });
      const audioUrl = URL.createObjectURL(audioBlob);
      const audio = new Audio(audioUrl);
      
      audio.onloadeddata = () => console.log("Audio loaded successfully");
      audio.onerror = (e) => console.error("Audio error:", e);
      
      audio.play().then(() => {
        console.log("Audio playback started");
      }).catch(e => {
        console.error("Error playing audio:", e);
        // Try alternative playback
        audio.load();
        audio.play();
      });
      
      // Clean up URL after playback
      audio.onended = () => URL.revokeObjectURL(audioUrl);
      
    } catch (error) {
      console.error("Error in playAudio:", error);
    }
  }

  function addToTranscript(text) {
    const transcript = document.getElementById('transcript');
    transcript.textContent += text + '\n';
    transcript.scrollTop = transcript.scrollHeight;
  }

  function updateStatus(message) {
    document.getElementById('status').textContent = message;
  }

  document.getElementById('start-btn').addEventListener('click', startConversation);
  document.getElementById('stop-btn').addEventListener('click', stopConversation);
</script>